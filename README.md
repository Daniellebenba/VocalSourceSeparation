# Audio Source Separation: D3Net on PodcastMix Data

### Final Project Submission: Danielle Ben-Bashat & Orly Koren


### Project Summary:

  * Fine-tuned and applied the D3Net model, a spectrogram-based architecture pre-trained on the MUSDB dataset, to investigate the feasibility of separating music and speech in podcasts. 
  * Particularly, leveraging the benefits of synthesized data.
  * Explored the performance of D3Net in this domain within our study, leveraging its prior training on a different dataset to evaluate adaptability and effectiveness on a new task.
  * Gain insights that could benefit podcast consumers, content creators, and the podcast industry, potentially introducing new playback possibilities and advanced analytics tools.




This Repo is Cloned from: https://github.com/sony/ai-research-code/

For implemented code, please go to: ai-research-code/d3net/music-source-separation
